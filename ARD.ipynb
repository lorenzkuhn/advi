{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzkuhn/advi/blob/main/ARD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WftQNyWmExQD",
        "outputId": "b7aa0f88-a09b-424e-83db-e2735d7ad712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.8.1-py3-none-any.whl (718 kB)\n",
            "\u001b[K     |████████████████████████████████| 718 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting torch>=1.11.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 11 kB/s \n",
            "\u001b[?25hCollecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (4.63.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11.0->pyro-ppl) (3.10.0.2)\n",
            "Installing collected packages: torch, pyro-api, pyro-ppl\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.8.1 torch-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyro-ppl "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import pyro\n",
        "from pyro.nn import PyroModule\n",
        "from pyro.nn import PyroSample\n",
        "from pyro.infer import MCMC, NUTS, HMC, Predictive\n",
        "from pyro.infer.autoguide import AutoDiagonalNormal\n",
        "from pyro.infer.autoguide import AutoContinuous\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "import pyro.distributions as dist\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "e_rlGFT2E4jg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making training data\n",
        "def make_training_data(num_samples, dims, sigma, mu=0):\n",
        "  \"\"\"\n",
        "  Creates training data when half of the regressors are 0\n",
        "  \"\"\"\n",
        "  x = np.random.randn(num_samples, dims).astype(np.float64)\n",
        "  w = sigma * np.random.randn(1,dims).astype(np.float64)\n",
        "  noise = np.random.randn(num_samples).astype(np.float64)\n",
        "  noise = 0\n",
        "  w[:,:int(dims/2)] = 0.\n",
        "  y = np.matmul(x, w.T) + (noise/2) + mu\n",
        "\n",
        "  y = torch.tensor(y, dtype = torch.float)\n",
        "  x = torch.tensor(x, dtype = torch.float)\n",
        "  return y, x, w\n",
        "\n",
        "\n",
        "def sep_training_test(y,x,test):\n",
        "  y_train = y[test:,:]\n",
        "  x_train = x[test:,:]\n",
        "  \n",
        "  y_test = y[:test,:]\n",
        "  x_test = x[:test,:]\n",
        "  return y_train, y_test, x_train, x_test\n",
        "\n",
        "num_features = 250\n",
        "\n",
        "y, x, w = make_training_data(11000, num_features, 10, mu=0)\n",
        "y_train, y_test, x_train, x_test = sep_training_test(y,x,1000)"
      ],
      "metadata": {
        "id": "sHqVY44ENbxv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bayesian model in pyro\n",
        "def model(x, y=None):\n",
        "      num_features = x.shape[1]\n",
        "\n",
        "      alpha = pyro.sample('alpha', dist.Gamma(torch.tensor([1.0]), torch.tensor([1.0])).expand([num_features]).to_event(1))\n",
        "      one_over_sqrt_alpha = 1/torch.sqrt(alpha)\n",
        "\n",
        "      sigma2 = pyro.sample('sigma2', dist.InverseGamma(torch.tensor([1.0]), torch.tensor([1.0])))\n",
        "      sigma = torch.sqrt(sigma2)\n",
        "\n",
        "      beta = pyro.sample('beta', dist.Normal(torch.tensor([0.0]), sigma*one_over_sqrt_alpha).expand([num_features]).to_event(1))\n",
        "\n",
        "      mean = torch.matmul(x, beta)\n",
        "\n",
        "      with pyro.plate(\"data\", x.shape[0]):          \n",
        "          outcome_dist = dist.Normal(mean, sigma)          \n",
        "          observation = pyro.sample(\"obs\", outcome_dist, obs=y)"
      ],
      "metadata": {
        "id": "l6p7-E48ZYbT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ADVI components: Guide, Optimizer and SVI\n",
        "guide = AutoDiagonalNormal(model)\n",
        "adaprop = pyro.optim.AdagradRMSProp(dict())\n",
        "svi = SVI(model, guide, adaprop, loss=Trace_ELBO())\n",
        "\n",
        "# Run ADVI \n",
        "pyro.clear_param_store()\n",
        "\n",
        "output_advi = pd.DataFrame(columns = [\"run_id\", \"t\", \"num_samples\", \"test_accuracy\", \"model\"])\n",
        "\n",
        "num_iterations = 20000\n",
        "step_ids = []\n",
        "step_time = []\n",
        "average_log_predictives = []\n",
        "mse_loss = nn.MSELoss()\n",
        "train_time = 0\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    # calculate the loss and take a gradient step\n",
        "    t0 = time.time()\n",
        "    loss = svi.step(x_train, y_train.squeeze())\n",
        "    t1 = time.time()\n",
        "    train_time += (t1-t0)     \n",
        "\n",
        "    if j % 100 == 0: #Evaluate model every 1000 samples\n",
        "      num_samples = 100\n",
        "      predictive_svi = Predictive(model, guide=guide, num_samples=num_samples)\n",
        "\n",
        "      train_predictions = predictive_svi(x_train, None)\n",
        "      test_predictions = predictive_svi(x_test, None)\n",
        "      train_obs = train_predictions['obs']\n",
        "      test_obs = test_predictions['obs']\n",
        "\n",
        "      average_train_log_mse = torch.log(mse_loss(train_obs, torch.tile(np.squeeze(y_train), (len(train_obs), 1))))\n",
        "      average_test_log_mse = torch.log(mse_loss(test_obs, torch.tile(np.squeeze(y_test), (len(test_obs), 1))))\n",
        "  \n",
        "      step_ids.append(j)\n",
        "      step_time.append(train_time)\n",
        "      average_log_predictives.append(average_test_log_mse)\n",
        "\n",
        "      output_iter = {\"run_id\":\"n/a\",\n",
        "                    \"t\":train_time,\n",
        "                    \"num_samples\":\"n/a\", \n",
        "                    \"test_accuracy\":average_test_log_mse.detach().numpy(),\n",
        "                    \"model\":\"advi\"}\n",
        "\n",
        "      output_advi = output_advi.append(output_iter, ignore_index = True)\n",
        "      print(\"[iteration %04d] loss: %.4f\" % (j + 1, average_test_log_mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMBWumSCMPjY",
        "outputId": "2c194912-c401-4708-f174-31d64d0b1733"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iteration 0001] loss: 9.0876\n",
            "[iteration 0101] loss: 8.1008\n",
            "[iteration 0201] loss: 7.3945\n",
            "[iteration 0301] loss: 4.6524\n",
            "[iteration 0401] loss: 0.0344\n",
            "[iteration 0501] loss: -1.0487\n",
            "[iteration 0601] loss: -1.2426\n",
            "[iteration 0701] loss: -1.6054\n",
            "[iteration 0801] loss: -1.8058\n",
            "[iteration 0901] loss: -1.8429\n",
            "[iteration 1001] loss: -2.0059\n",
            "[iteration 1101] loss: -1.9807\n",
            "[iteration 1201] loss: -1.8581\n",
            "[iteration 1301] loss: -2.1227\n",
            "[iteration 1401] loss: -2.4624\n",
            "[iteration 1501] loss: -2.4404\n",
            "[iteration 1601] loss: -2.4256\n",
            "[iteration 1701] loss: -2.5614\n",
            "[iteration 1801] loss: -2.4180\n",
            "[iteration 1901] loss: -2.5049\n",
            "[iteration 2001] loss: -2.6483\n",
            "[iteration 2101] loss: -2.5759\n",
            "[iteration 2201] loss: -2.6479\n",
            "[iteration 2301] loss: -2.7055\n",
            "[iteration 2401] loss: -2.8177\n",
            "[iteration 2501] loss: -2.8821\n",
            "[iteration 2601] loss: -2.8735\n",
            "[iteration 2701] loss: -2.9761\n",
            "[iteration 2801] loss: -3.0938\n",
            "[iteration 2901] loss: -2.8803\n",
            "[iteration 3001] loss: -3.1240\n",
            "[iteration 3101] loss: -3.0063\n",
            "[iteration 3201] loss: -3.0557\n",
            "[iteration 3301] loss: -3.1288\n",
            "[iteration 3401] loss: -3.0131\n",
            "[iteration 3501] loss: -3.2130\n",
            "[iteration 3601] loss: -3.2256\n",
            "[iteration 3701] loss: -3.2863\n",
            "[iteration 3801] loss: -3.2931\n",
            "[iteration 3901] loss: -3.3250\n",
            "[iteration 4001] loss: -3.3656\n",
            "[iteration 4101] loss: -3.4216\n",
            "[iteration 4201] loss: -3.3782\n",
            "[iteration 4301] loss: -3.3946\n",
            "[iteration 4401] loss: -3.4712\n",
            "[iteration 4501] loss: -3.3370\n",
            "[iteration 4601] loss: -3.5179\n",
            "[iteration 4701] loss: -3.5486\n",
            "[iteration 4801] loss: -3.5791\n",
            "[iteration 4901] loss: -3.4615\n",
            "[iteration 5001] loss: -3.6541\n",
            "[iteration 5101] loss: -3.4601\n",
            "[iteration 5201] loss: -3.5388\n",
            "[iteration 5301] loss: -3.7578\n",
            "[iteration 5401] loss: -3.6456\n",
            "[iteration 5501] loss: -3.5055\n",
            "[iteration 5601] loss: -3.7388\n",
            "[iteration 5701] loss: -3.7293\n",
            "[iteration 5801] loss: -3.5853\n",
            "[iteration 5901] loss: -3.6696\n",
            "[iteration 6001] loss: -3.7882\n",
            "[iteration 6101] loss: -3.7798\n",
            "[iteration 6201] loss: -3.6739\n",
            "[iteration 6301] loss: -3.8977\n",
            "[iteration 6401] loss: -3.8260\n",
            "[iteration 6501] loss: -3.7720\n",
            "[iteration 6601] loss: -3.7981\n",
            "[iteration 6701] loss: -3.8771\n",
            "[iteration 6801] loss: -3.9092\n",
            "[iteration 6901] loss: -3.8422\n",
            "[iteration 7001] loss: -3.8333\n",
            "[iteration 7101] loss: -3.9672\n",
            "[iteration 7201] loss: -3.8264\n",
            "[iteration 7301] loss: -3.9369\n",
            "[iteration 7401] loss: -4.0450\n",
            "[iteration 7501] loss: -3.8656\n",
            "[iteration 7601] loss: -4.0535\n",
            "[iteration 7701] loss: -4.0175\n",
            "[iteration 7801] loss: -3.9619\n",
            "[iteration 7901] loss: -4.0000\n",
            "[iteration 8001] loss: -3.9694\n",
            "[iteration 8101] loss: -4.1521\n",
            "[iteration 8201] loss: -4.0309\n",
            "[iteration 8301] loss: -4.1222\n",
            "[iteration 8401] loss: -4.1970\n",
            "[iteration 8501] loss: -4.0954\n",
            "[iteration 8601] loss: -4.0163\n",
            "[iteration 8701] loss: -4.0868\n",
            "[iteration 8801] loss: -3.9422\n",
            "[iteration 8901] loss: -4.0490\n",
            "[iteration 9001] loss: -4.1637\n",
            "[iteration 9101] loss: -4.1992\n",
            "[iteration 9201] loss: -4.2087\n",
            "[iteration 9301] loss: -4.1057\n",
            "[iteration 9401] loss: -4.2241\n",
            "[iteration 9501] loss: -4.2517\n",
            "[iteration 9601] loss: -4.1784\n",
            "[iteration 9701] loss: -4.1815\n",
            "[iteration 9801] loss: -4.3590\n",
            "[iteration 9901] loss: -4.2703\n",
            "[iteration 10001] loss: -4.2013\n",
            "[iteration 10101] loss: -4.3403\n",
            "[iteration 10201] loss: -4.1988\n",
            "[iteration 10301] loss: -4.2635\n",
            "[iteration 10401] loss: -4.2176\n",
            "[iteration 10501] loss: -4.2936\n",
            "[iteration 10601] loss: -4.2957\n",
            "[iteration 10701] loss: -4.3091\n",
            "[iteration 10801] loss: -4.3202\n",
            "[iteration 10901] loss: -4.3060\n",
            "[iteration 11001] loss: -4.3997\n",
            "[iteration 11101] loss: -4.3380\n",
            "[iteration 11201] loss: -4.3741\n",
            "[iteration 11301] loss: -4.3798\n",
            "[iteration 11401] loss: -4.4087\n",
            "[iteration 11501] loss: -4.3443\n",
            "[iteration 11601] loss: -4.3850\n",
            "[iteration 11701] loss: -4.3461\n",
            "[iteration 11801] loss: -4.4777\n",
            "[iteration 11901] loss: -4.3830\n",
            "[iteration 12001] loss: -4.4584\n",
            "[iteration 12101] loss: -4.5450\n",
            "[iteration 12201] loss: -4.4958\n",
            "[iteration 12301] loss: -4.3928\n",
            "[iteration 12401] loss: -4.4543\n",
            "[iteration 12501] loss: -4.3906\n",
            "[iteration 12601] loss: -4.3687\n",
            "[iteration 12701] loss: -4.4984\n",
            "[iteration 12801] loss: -4.5159\n",
            "[iteration 12901] loss: -4.4829\n",
            "[iteration 13001] loss: -4.4726\n",
            "[iteration 13101] loss: -4.4275\n",
            "[iteration 13201] loss: -4.4732\n",
            "[iteration 13301] loss: -4.4175\n",
            "[iteration 13401] loss: -4.5646\n",
            "[iteration 13501] loss: -4.5583\n",
            "[iteration 13601] loss: -4.5345\n",
            "[iteration 13701] loss: -4.5786\n",
            "[iteration 13801] loss: -4.4797\n",
            "[iteration 13901] loss: -4.5682\n",
            "[iteration 14001] loss: -4.5413\n",
            "[iteration 14101] loss: -4.4802\n",
            "[iteration 14201] loss: -4.4909\n",
            "[iteration 14301] loss: -4.3973\n",
            "[iteration 14401] loss: -4.6671\n",
            "[iteration 14501] loss: -4.5296\n",
            "[iteration 14601] loss: -4.6098\n",
            "[iteration 14701] loss: -4.6275\n",
            "[iteration 14801] loss: -4.5462\n",
            "[iteration 14901] loss: -4.5437\n",
            "[iteration 15001] loss: -4.7606\n",
            "[iteration 15101] loss: -4.5393\n",
            "[iteration 15201] loss: -4.7271\n",
            "[iteration 15301] loss: -4.6745\n",
            "[iteration 15401] loss: -4.7144\n",
            "[iteration 15501] loss: -4.6266\n",
            "[iteration 15601] loss: -4.7230\n",
            "[iteration 15701] loss: -4.6486\n",
            "[iteration 15801] loss: -4.7629\n",
            "[iteration 15901] loss: -4.7680\n",
            "[iteration 16001] loss: -4.7323\n",
            "[iteration 16101] loss: -4.7349\n",
            "[iteration 16201] loss: -4.6950\n",
            "[iteration 16301] loss: -4.7222\n",
            "[iteration 16401] loss: -4.7371\n",
            "[iteration 16501] loss: -4.7060\n",
            "[iteration 16601] loss: -4.8045\n",
            "[iteration 16701] loss: -4.8460\n",
            "[iteration 16801] loss: -4.7150\n",
            "[iteration 16901] loss: -4.8114\n",
            "[iteration 17001] loss: -4.7559\n",
            "[iteration 17101] loss: -4.7972\n",
            "[iteration 17201] loss: -4.8729\n",
            "[iteration 17301] loss: -4.7603\n",
            "[iteration 17401] loss: -4.7742\n",
            "[iteration 17501] loss: -4.8453\n",
            "[iteration 17601] loss: -4.8366\n",
            "[iteration 17701] loss: -4.7802\n",
            "[iteration 17801] loss: -4.7233\n",
            "[iteration 17901] loss: -4.9636\n",
            "[iteration 18001] loss: -4.7043\n",
            "[iteration 18101] loss: -4.8820\n",
            "[iteration 18201] loss: -4.8555\n",
            "[iteration 18301] loss: -4.7469\n",
            "[iteration 18401] loss: -4.8450\n",
            "[iteration 18501] loss: -4.9757\n",
            "[iteration 18601] loss: -4.8901\n",
            "[iteration 18701] loss: -4.9553\n",
            "[iteration 18801] loss: -4.8593\n",
            "[iteration 18901] loss: -4.8810\n",
            "[iteration 19001] loss: -4.8462\n",
            "[iteration 19101] loss: -4.8806\n",
            "[iteration 19201] loss: -4.9076\n",
            "[iteration 19301] loss: -4.8211\n",
            "[iteration 19401] loss: -4.8317\n",
            "[iteration 19501] loss: -4.8607\n",
            "[iteration 19601] loss: -4.8540\n",
            "[iteration 19701] loss: -4.7284\n",
            "[iteration 19801] loss: -4.9553\n",
            "[iteration 19901] loss: -4.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size_l = np.arange(50, 500, 50)\n",
        "sample_size_s = np.arange(5, 50, 10)\n",
        "sample_size = np.concatenate((sample_size_s, sample_size_l))\n",
        "\n",
        "for i in sample_size:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAjtiG6epOO5",
        "outputId": "fbad7c77-e1ab-41ba-b858-9a23854a967e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "15\n",
            "25\n",
            "35\n",
            "45\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run MCMC using Stan kernel\n",
        "pyro.clear_param_store()\n",
        "\n",
        "output_mcmc = pd.DataFrame(columns = [\"run_id\", \"t\", \"num_samples\", \"test_accuracy\", \"model\"])\n",
        "\n",
        "sample_size_l = np.arange(50, 700, 50)\n",
        "sample_size_s = np.arange(2, 50, 10)\n",
        "sample_size = np.concatenate((sample_size_s, sample_size_l))\n",
        "\n",
        "for size in sample_size: \n",
        "  \n",
        "    num_samples = size\n",
        "    num_warmups = size\n",
        "    \n",
        "    print('Num samples: {}'.format(num_samples))\n",
        "\n",
        "    nuts_kernel = NUTS(model,\n",
        "                       max_tree_depth = 4)\n",
        "\n",
        "    mcmc = MCMC(\n",
        "            nuts_kernel,\n",
        "            num_samples=num_samples,\n",
        "            warmup_steps=num_warmups,\n",
        "            disable_progbar=False,\n",
        "            num_chains = 1\n",
        "    ) \n",
        "\n",
        "    start = time.time()\n",
        "    mcmc.run(x_train, y_train.squeeze())\n",
        "    end = time.time()\n",
        "\n",
        "    samples = mcmc.get_samples()\n",
        "    mcmc_predictive = Predictive(model, samples)\n",
        "    test_obs = mcmc_predictive(x_test, None)['obs']\n",
        "    average_test_log_accuracy = torch.mean(torch.log(mse_loss(test_obs, torch.tile(np.squeeze(y_test), (len(test_obs), 1)))))\n",
        "\n",
        "    output_iter = {\"run_id\":\"n/a\",\n",
        "                  \"t\":end-start,\n",
        "                  \"num_samples\":num_samples, \n",
        "                  \"test_accuracy\":average_test_log_accuracy.detach().numpy(),\n",
        "                  \"model\":\"nuts\"}\n",
        "\n",
        "    output_mcmc = output_mcmc.append(output_iter, ignore_index = True)\n",
        "    print(average_test_log_accuracy)"
      ],
      "metadata": {
        "id": "VIBh7h2muCl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b4b0d6-d692-4b53-c2f5-74a4c9240e9e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num samples: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 4/4 [00:00, 22.25it/s, step size=1.76e-03, acc. prob=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.2790)\n",
            "Num samples: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 24/24 [00:01, 13.25it/s, step size=6.03e-03, acc. prob=0.990]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.9074)\n",
            "Num samples: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 44/44 [00:01, 24.65it/s, step size=2.35e-02, acc. prob=0.082]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.7912)\n",
            "Num samples: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 64/64 [00:04, 14.32it/s, step size=1.26e-02, acc. prob=0.748]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.7184)\n",
            "Num samples: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 84/84 [00:04, 18.02it/s, step size=7.16e-02, acc. prob=0.169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.9759)\n",
            "Num samples: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 100/100 [00:06, 15.76it/s, step size=2.20e-02, acc. prob=0.408]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.9795)\n",
            "Num samples: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 200/200 [00:11, 17.52it/s, step size=7.30e-03, acc. prob=0.028]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0556)\n",
            "Num samples: 150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 300/300 [00:23, 12.85it/s, step size=9.57e-03, acc. prob=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0840)\n",
            "Num samples: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 400/400 [00:31, 12.78it/s, step size=1.36e-02, acc. prob=0.912]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.0626)\n",
            "Num samples: 250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 500/500 [00:39, 12.77it/s, step size=1.19e-02, acc. prob=0.869]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.4485)\n",
            "Num samples: 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 600/600 [00:47, 12.74it/s, step size=1.65e-01, acc. prob=0.459]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.3024)\n",
            "Num samples: 350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 700/700 [00:54, 12.86it/s, step size=9.66e-02, acc. prob=0.773]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.3000)\n",
            "Num samples: 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 800/800 [01:01, 13.06it/s, step size=8.23e-02, acc. prob=0.834]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.4708)\n",
            "Num samples: 450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 900/900 [01:08, 13.15it/s, step size=1.03e-01, acc. prob=0.604]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.7566)\n",
            "Num samples: 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 1000/1000 [01:16, 13.01it/s, step size=2.47e-02, acc. prob=0.449]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-7.2436)\n",
            "Num samples: 550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 1100/1100 [01:24, 13.06it/s, step size=3.01e-02, acc. prob=0.212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-7.6767)\n",
            "Num samples: 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 1200/1200 [01:32, 13.02it/s, step size=2.68e-02, acc. prob=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-7.4915)\n",
            "Num samples: 650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 1300/1300 [01:38, 13.15it/s, step size=3.10e-02, acc. prob=0.209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-7.5694)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate plot (Figure 4 in original paper)\n",
        "\n",
        "output = output_advi.append(output_mcmc, ignore_index=True)\n",
        "output = output.loc[output['t'] < 100]\n",
        "output['test_accuracy'] = output['test_accuracy'].astype('float')\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "results = sns.lineplot(data = output, x = 't', y = 'test_accuracy', hue = 'model')\n",
        "results.set(xscale='log', \n",
        "            xlim = (0.015, 150), \n",
        "            xlabel = 'Seconds',\n",
        "            ylabel = 'Average Log Predictive')\n",
        "plt.legend(labels=[\"ADVI (M=1)\",\"NUTS\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "J2OSCCNNgp_w",
        "outputId": "c36bb63e-1070-4b28-be81-9ff604119e7d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa4d77f4b50>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nAqjs9y2w2Bx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}